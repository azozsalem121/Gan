## الخطوة 5: تقييم أداء نماذج التصنيف ومقارنة النتائج

في هذه الخطوة، قمنا بتقييم أداء نماذج التصنيف (Random Forest و MLP Neural Network) على مجموعتي البيانات: المجموعة الأصلية غير المتوازنة والمجموعة المتوازنة التي تم إنشاؤها باستخدام Vanilla GAN. كما قمنا بإنشاء رسوم بيانية لمقارنة الأداء وتحليل النتائج.

### ملخص النتائج:

| النموذج | مجموعة البيانات | الدقة (Accuracy) | الضبط (Precision) | الاستدعاء (Recall) | درجة F1 |
|---------|-----------------|-----------------|-------------------|-------------------|---------|
| Random Forest | الأصلية غير المتوازنة | 0.7638 | 0.7492 | 0.7638 | 0.7493 |
| Random Forest | المتوازنة (Vanilla GAN) | 0.8356 | 0.8421 | 0.8356 | 0.8344 |
| MLP Neural Network | الأصلية غير المتوازنة | 0.7141 | 0.7188 | 0.7141 | 0.7163 |
| MLP Neural Network | المتوازنة (Vanilla GAN) | 0.7988 | 0.7992 | 0.7988 | 0.7968 |

### 1. مقارنة مقاييس الأداء:

![مقارنة مقاييس الأداء](metrics_comparison.png)

نلاحظ من الرسم البياني أعلاه:
- تفوق نموذج Random Forest على نموذج MLP Neural Network في جميع المقاييس.
- تحسن أداء كلا النموذجين بشكل ملحوظ عند استخدام البيانات المتوازنة.
- حقق نموذج Random Forest على البيانات المتوازنة أفضل أداء بشكل عام، مع دقة تصل إلى 83.56% ودرجة F1 تصل إلى 83.44%.

### 2. نسبة التحسن باستخدام البيانات المتوازنة:

![نسبة التحسن](improvement_chart.png)

يوضح الرسم البياني أعلاه نسبة التحسن في مقاييس الأداء عند استخدام البيانات المتوازنة مقارنة بالبيانات الأصلية غير المتوازنة:
- تحسن أداء نموذج Random Forest بنسبة 9.5% في الدقة و 11.4% في درجة F1.
- تحسن أداء نموذج MLP Neural Network بنسبة 11.9% في الدقة و 11.2% في درجة F1.
- نلاحظ أن نموذج MLP استفاد بشكل أكبر من موازنة البيانات من حيث نسبة التحسن، على الرغم من أن نموذج Random Forest حقق أداءً أفضل بشكل مطلق.

### 3. أداء التصنيف لكل فئة:

![أداء التصنيف لكل فئة](class_performance.png)

يوضح الرسم البياني أعلاه درجة F1 لكل فئة من فئات التصنيف:
- **فئة Dropout:** حقق كلا النموذجين أداءً جيدًا نسبيًا في تصنيف هذه الفئة، مع تحسن طفيف عند استخدام البيانات المتوازنة.
- **فئة Enrolled (الفئة الأقلية):** شهدت تحسنًا كبيرًا جدًا في التصنيف عند استخدام البيانات المتوازنة:
  * في نموذج Random Forest: ارتفعت درجة F1 من 0.43 إلى 0.84 (تحسن بنسبة 95%).
  * في نموذج MLP Neural Network: ارتفعت درجة F1 من 0.43 إلى 0.79 (تحسن بنسبة 84%).
- **فئة Graduate (الفئة الأكثر عددًا):** حافظت على أداء جيد في جميع السيناريوهات، مع تحسن طفيف عند استخدام البيانات المتوازنة.

### 4. مصفوفات الارتباك (Confusion Matrices):

![مصفوفات الارتباك](confusion_matrices.png)

توضح مصفوفات الارتباك أعلاه تفاصيل التنبؤات الصحيحة والخاطئة لكل نموذج:
- **نموذج Random Forest على البيانات الأصلية:** يظهر ضعفًا في تصنيف فئة Enrolled، حيث تم تصنيف 40 حالة خطأً كـ Dropout و 63 حالة خطأً كـ Graduate.
- **نموذج Random Forest على البيانات المتوازنة:** تحسن كبير في تصنيف فئة Enrolled، مع زيادة عدد التصنيفات الصحيحة من 56 إلى 347.
- **نموذج MLP Neural Network على البيانات الأصلية:** أداء ضعيف في تصنيف فئة Enrolled، وأخطاء كثيرة في تصنيف فئة Graduate.
- **نموذج MLP Neural Network على البيانات المتوازنة:** تحسن كبير في تصنيف فئة Enrolled، مع زيادة عدد التصنيفات الصحيحة من 70 إلى 354.

### الاستنتاجات الرئيسية:

1. **تأثير موازنة البيانات:** أدت موازنة البيانات باستخدام Vanilla GAN إلى تحسين كبير في أداء التصنيف لكلا النموذجين، خاصة في تصنيف الفئة الأقلية (Enrolled).

2. **مقارنة النماذج:** تفوق نموذج Random Forest على نموذج MLP Neural Network في جميع السيناريوهات، مما يشير إلى أنه أكثر ملاءمة لهذه المشكلة.

3. **تصنيف الفئة الأقلية:** كان التحسن الأكبر في تصنيف فئة Enrolled (الفئة الأقلية)، حيث ارتفعت درجة F1 بنسبة تصل إلى 95% عند استخدام البيانات المتوازنة.

4. **الاستقرار:** حافظت الفئات الأخرى (Dropout و Graduate) على أداء جيد أو تحسنت قليلاً، مما يشير إلى أن موازنة البيانات لم تؤثر سلبًا على تصنيف الفئات الأخرى.

### التوصيات:

1. **استخدام البيانات المتوازنة:** نوصي باستخدام البيانات المتوازنة باستخدام Vanilla GAN لتحسين أداء التصنيف، خاصة عندما يكون التركيز على تصنيف الفئات الأقلية.

2. **اختيار النموذج:** نوصي باستخدام نموذج Random Forest لهذه المشكلة، حيث أظهر أداءً أفضل من MLP Neural Network في جميع السيناريوهات.

3. **تطبيقات مستقبلية:** يمكن تطبيق هذا النهج (استخدام GAN لموازنة البيانات) على مشكلات تصنيف أخرى تعاني من عدم توازن البيانات.

4. **تحسينات محتملة:** يمكن تجربة أنواع أخرى من نماذج GAN المتقدمة (مثل CGAN أو WGAN-GP) لتوليد بيانات اصطناعية أكثر جودة، أو تجربة تقنيات موازنة بيانات أخرى (مثل SMOTE) للمقارنة.
